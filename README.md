# ğŸ” Sherlog Prometheus Agent

> ğŸ¤– An LLM-powered agent for querying and analyzing observability data using natural language.

## âœ¨ Features

- ğŸ’¬ Natural language queries for Prometheus metrics and Loki logs
- ğŸ§  Automated analysis and correlation of metrics and logs
- ğŸ“Š Integration with Grafana for visualization
- ğŸ”Œ Support for custom backends and query engines

## ğŸš€ Getting Started

### Production Setup

For production deployment, use the standard docker-compose file:

```bash
docker compose up --build
```

This starts the core services:
- ğŸ¤– Sherlog Agent (port 8000)
- ğŸ“ Redis for caching

### Demo Environment

For testing and development, we provide a full demo environment with monitoring stack:

```bash
docker compose -f docker-compose.demo.yml up --build
```

The demo environment includes:
- ğŸ¤– Sherlog Agent (port 8000)
- ğŸ“ Redis for caching
- ğŸ“Š Prometheus (port 9090)
- ğŸ“ Loki (port 3100)
- ğŸ“ˆ Grafana (port 3000)
- ğŸ“¡ Promtail for log collection
- ğŸ“Š Node Exporter for system metrics
- ğŸŒŸ Sample Application (port 8080)

All services in the demo environment are configured with:
- Pre-configured monitoring
- Log aggregation via Loki
- Metrics collection via Prometheus
- Ready-to-use Grafana dashboards

For detailed information about the demo environment, see [DEMO.md](docs/DEMO.md)

## ğŸ® Demo Application

The project includes a demo application that simulates a real-world service with:

- ğŸ‘¥ Active user metrics
- ğŸ›’ Order processing statistics
- ğŸ“ˆ System performance metrics (CPU, Memory)
- ğŸ“ Various log levels (INFO, WARNING, ERROR)
- ğŸŒ HTTP request metrics

### ğŸš€ Running the Demo

1. Start the demo stack:
```bash
# Navigate to demo directory and start services
cd app/demo
docker-compose up --build
```

This will start:
- ğŸŒŸ Demo FastAPI application (`port 8000`)
- ğŸ“Š Prometheus (`port 9090`)
- ğŸ“ Loki (`port 3100`)
- ğŸ“ˆ Grafana (`port 3000`)
- ğŸ“¡ Promtail for log collection
- ğŸ¤– Observability Agent (`port 5000`)

2. Try example queries:
```bash
# Run the demo script
cd app/demo
python agent_demo.py
```

### ğŸ’¡ Example Queries

```text
ğŸ“Š "Show me the error rate in the last hour"
ğŸ’» "What's the current CPU and memory usage?"
âŒ "Show me all failed orders in the last 30 minutes"
â±ï¸ "What's the average request latency by endpoint?"
ğŸš¨ "Are there any system performance issues?"
ğŸ” "Show me the correlation between high CPU usage and error rates"
```

### ğŸ“Š Demo Metrics and Logs

The demo application generates:

#### 1. Metrics
| Metric | Description | Range |
|--------|-------------|-------|
| `active_users` | Number of active users | 50-200 |
| `orders_processed` | Order processing counter | - |
| `cpu_usage_percent` | Simulated CPU usage | 20-80% |
| `memory_usage_percent` | Simulated memory usage | 30-90% |
| `http_requests_total` | HTTP request counter | - |
| `http_request_duration_seconds` | Request latency histogram | - |

#### 2. Logs
- â„¹ï¸ **INFO**: Active user counts and successful orders
- âš ï¸ **WARNING**: High CPU/memory usage alerts
- âŒ **ERROR**: Failed orders and system errors
- ğŸ”„ Various error scenarios:
  - Database connection timeouts
  - Payment processing failures
  - API availability issues
  - Cache misses
  - Rate limit violations

### ğŸ”— Accessing Services

#### ğŸŒŸ Demo App: `http://localhost:8000`
```text
GET /          - Root endpoint
GET /metrics   - Prometheus metrics
GET /error     - Test error endpoint
```

#### ğŸ“Š Prometheus: `http://localhost:9090`
- View raw metrics
- Execute PromQL queries
- Check targets status

#### ğŸ“ˆ Grafana: `http://localhost:3000`
> ğŸ”‘ Credentials: `admin`/`admin`
- Pre-configured datasources
- Create dashboards
- View query results

## ğŸ‘©â€ğŸ’» Development Setup

1. Create virtual environment:
```bash
# Create and activate virtual environment
python -m venv venv

# On Unix/macOS:
source venv/bin/activate

# On Windows:
.\venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run tests:
```bash
pytest tests/
```

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ core/                 # ğŸ¯ Core agent functionality
â”‚   â”œâ”€â”€ agent.py         # ğŸ¤– Main agent implementation
â”‚   â”œâ”€â”€ backends/        # ğŸ”Œ Backend implementations
â”‚   â”œâ”€â”€ models/          # ğŸ“Š Data models
â”‚   â”œâ”€â”€ tools/           # ğŸ”§ Agent tools
â”‚   â””â”€â”€ visualizations/  # ğŸ“ˆ Visualization utilities
â”œâ”€â”€ demo/                # ğŸ® Demo application
â”‚   â”œâ”€â”€ main.py         # ğŸŒŸ FastAPI demo app
â”‚   â”œâ”€â”€ agent_demo.py   # ğŸ¤– Demo script
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ tests/              # âœ… Test suite
```

## ğŸ¤ Contributing

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch
3. âœ¨ Make your changes
4. ğŸ§ª Run tests
5. ğŸ“¤ Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

---
<div align="center">
Made with â¤ï¸ for the observability community
</div>

# Sherlog

A powerful log analysis and metrics monitoring tool with an AI-powered chat interface.

## Quick Start

### Easy Setup (Recommended)

1. Clone the repository:
```bash
git clone https://github.com/yourusername/sherlog.git
cd sherlog
```

2. Run the setup script:
```bash
chmod +x setup.sh
./setup.sh
```

3. Start both frontend and backend:
```bash
cd frontend
npm run dev:all
```

The application will be available at http://localhost:3000

### Manual Setup

If you prefer to set up manually:

1. Set up the Python environment:
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

2. Set up the frontend:
```bash
cd frontend
npm install
```

3. Create necessary environment files:
```bash
# In the root directory
cp .env.example .env

# In the frontend directory
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local
```

4. Start the servers:
```bash
# In one terminal (backend)
source venv/bin/activate
python -m uvicorn app.main:app --reload

# In another terminal (frontend)
cd frontend
npm run dev
```

## Project Structure

```
sherlog/
â”œâ”€â”€ app/                 # Backend application
â”‚   â”œâ”€â”€ core/           # Core functionality
â”‚   â”œâ”€â”€ routers/        # API routes
â”‚   â””â”€â”€ main.py         # Main application entry
â”œâ”€â”€ frontend/           # Next.js frontend
â”‚   â”œâ”€â”€ app/           # Frontend pages
â”‚   â”œâ”€â”€ components/    # React components
â”‚   â””â”€â”€ lib/          # Frontend utilities
â”œâ”€â”€ tests/             # Test suite
â””â”€â”€ docs/              # Documentation
```

## Features

- ğŸ¤– AI-powered log analysis
- ğŸ“Š Prometheus/Loki/Grafana integration
- ğŸ“ Natural language queries
- ğŸ“ˆ Real-time metrics monitoring
- ğŸ¨ Modern web interface
- ğŸ”„ Real-time streaming responses

## Development

- Backend API: http://localhost:8000
- Frontend: http://localhost:3000
- API Documentation: http://localhost:8000/docs

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a new Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details. 