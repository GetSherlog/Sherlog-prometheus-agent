services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      # LLM Configuration
      - LLM__PROVIDER=${LLM__PROVIDER:-gemini}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LLM__GEMINI_MODEL=${LLM__GEMINI_MODEL:-gemini-2.0-flash}
      # Optional LLM providers
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM__OLLAMA_HOST=${LLM__OLLAMA_HOST:-}
      
      # Prometheus Configuration
      - PROMETHEUS__URL=${PROMETHEUS__URL:-http://localhost:9090}
      - PROMETHEUS__TIMEOUT=${PROMETHEUS__TIMEOUT:-30}
      - PROMETHEUS__MAX_RETRIES=${PROMETHEUS__MAX_RETRIES:-3}
      - PROMETHEUS__RETRY_BACKOFF=${PROMETHEUS__RETRY_BACKOFF:-1.5}
      
      # Cache Configuration
      - CACHE__TYPE=${CACHE__TYPE:-memory}
      - CACHE__TTL=${CACHE__TTL:-3600}
      
      # Optional Slack Integration
      - SLACK__ENABLED=${SLACK__ENABLED:-false}
      - SLACK__BOT_TOKEN=${SLACK__BOT_TOKEN:-}
      - SLACK__APP_TOKEN=${SLACK__APP_TOKEN:-}
      - SLACK__DEFAULT_CHANNEL=${SLACK__DEFAULT_CHANNEL:-monitoring}
      
      # Redis Configuration (if using redis cache)
      - REDIS__URL=${REDIS__URL:-redis://redis:6379/0}
      - REDIS__MAX_CONNECTIONS=${REDIS__MAX_CONNECTIONS:-10}
      - REDIS__TIMEOUT=${REDIS__TIMEOUT:-5}
    depends_on:
      - redis
    volumes:
      - ./app:/app/app
    networks:
      - sherlog-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - sherlog-network

networks:
  sherlog-network:
    driver: bridge 